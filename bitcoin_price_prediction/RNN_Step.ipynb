{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAll in all, an RNN is a for loop that reuses quantities computed\\nduring the previous iteration of the loop, nothing more; \\n\\n\\nThe above for-loop corresponds to a Keras layer:\\n    SimpleRNN\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This RNN takes as input a sequence of vectors, which \n",
    "you'll encode as a 2D tensor of size (timesteps, input_features).\n",
    "It loops over timesteps, and at each timestep, it considers its \n",
    "current state at t and the input at t (of shape input_features)\n",
    "and combines them to obtain the output at t. \n",
    "Then the state for the next step is set to be this previous output.\n",
    "\n",
    "For the first tiimestep, the previous output isnt defined=>\n",
    "no current state => this initial state is initialized as an \n",
    "all zero vector called the initial state of the network\n",
    "\"\"\"\n",
    "# Nr of timesteps in the input sequence\n",
    "timesteps = 100\n",
    "# Dimensionality of the input feature space\n",
    "input_features = 32\n",
    "# Dimensionality of the output feature space\n",
    "output_features = 64\n",
    "\n",
    "# Input data; random noise for the sake of the example;lol\n",
    "inputs = np.random.random((timesteps, input_features))\n",
    "\n",
    "# Initial state; an all-zero vector\n",
    "state_t = np.zeros((output_features,))\n",
    "\n",
    "# Creating random weight matrices\n",
    "W = np.random.random((output_features, input_features))\n",
    "U = np.random.random((output_features, output_features))\n",
    "b = np.random.random((output_features,))\n",
    "\n",
    "successive_outputs = []\n",
    "\n",
    "\n",
    "state_t = 0\n",
    "# Input_t is a vector of shape(input_features,)\n",
    "for input_t in inputs:\n",
    "    # Combines the input with the current state (previous output)\n",
    "    # to obtain the current output\n",
    "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "    # Stores this output in a list\n",
    "    successive_outputs.append(output_t)\n",
    "    # Updates the state of the network for the next timestep\n",
    "    state_t = output_t \n",
    "    \n",
    "\"\"\"\n",
    "Updates the state of the network for the next timestep\n",
    "The final output is a 2D tensor of shape (timesteps, output_features)\n",
    "\"\"\"\n",
    "final_output_sequence = np.concatenate(successive_outputs, axis=0)    \n",
    "\n",
    "\"\"\"\n",
    "All in all, an RNN is a for loop that reuses quantities computed\n",
    "during the previous iteration of the loop, nothing more; \n",
    "\n",
    "\n",
    "The above for-loop corresponds to a Keras layer:\n",
    "    SimpleRNN\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 322,080\n",
      "Trainable params: 322,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, None, 32)          2080      \n",
      "=================================================================\n",
      "Total params: 322,080\n",
      "Trainable params: 322,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "# Returns the full state of sequences\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 328,320\n",
      "Trainable params: 328,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sometimes its useful to stack several recurrent layers one\n",
    "after the other in order to increase the representational power of\n",
    "a network. \n",
    "In such a setup, you have to get all of the intermediate layers\n",
    "to return full sequence of outputs:\n",
    "\"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "# Returns the full state of sequences\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 126s 7us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "input_train shape: (25000, 500)\n",
      "input_test shape: (25000, 500)\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.6452 - acc: 0.6108 - val_loss: 0.5881 - val_acc: 0.6796\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.4312 - acc: 0.8146 - val_loss: 0.4037 - val_acc: 0.8260\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 20s 977us/step - loss: 0.3034 - acc: 0.8802 - val_loss: 0.3440 - val_acc: 0.8620\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 19s 973us/step - loss: 0.2371 - acc: 0.9093 - val_loss: 0.5420 - val_acc: 0.7826\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 18s 901us/step - loss: 0.1898 - acc: 0.9276 - val_loss: 0.3575 - val_acc: 0.8692\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 18s 884us/step - loss: 0.1401 - acc: 0.9505 - val_loss: 0.4174 - val_acc: 0.8276\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 20s 980us/step - loss: 0.0940 - acc: 0.9696 - val_loss: 0.4086 - val_acc: 0.8576\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 18s 883us/step - loss: 0.0609 - acc: 0.9810 - val_loss: 0.5082 - val_acc: 0.8198\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 18s 888us/step - loss: 0.0378 - acc: 0.9886 - val_loss: 0.5156 - val_acc: 0.8382\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 16s 817us/step - loss: 0.0269 - acc: 0.9923 - val_loss: 0.6280 - val_acc: 0.8094\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 500\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
    "num_words=max_features)\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)\n",
    "\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train,\n",
    "epochs=10,\n",
    "batch_size=128,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 55s 3ms/step - loss: 0.5094 - acc: 0.7609 - val_loss: 0.3735 - val_acc: 0.8622\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 56s 3ms/step - loss: 0.2887 - acc: 0.8879 - val_loss: 0.3702 - val_acc: 0.8336\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 50s 2ms/step - loss: 0.2356 - acc: 0.9107 - val_loss: 0.3380 - val_acc: 0.8820\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 50s 3ms/step - loss: 0.1972 - acc: 0.9259 - val_loss: 0.4017 - val_acc: 0.8644\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 50s 3ms/step - loss: 0.1721 - acc: 0.9375 - val_loss: 0.3502 - val_acc: 0.8738\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 55s 3ms/step - loss: 0.1544 - acc: 0.9443 - val_loss: 0.4235 - val_acc: 0.8576\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 52s 3ms/step - loss: 0.1415 - acc: 0.9493 - val_loss: 0.3020 - val_acc: 0.8832\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 0.1294 - acc: 0.9552 - val_loss: 0.3504 - val_acc: 0.8734\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 52s 3ms/step - loss: 0.1159 - acc: 0.9607 - val_loss: 0.3333 - val_acc: 0.8838\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 56s 3ms/step - loss: 0.1104 - acc: 0.9605 - val_loss: 0.5746 - val_acc: 0.8552\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2 otehr RNN layers in keras are: LSTM and GRU\n",
    "In practice, you'll always sue one of these, because SimpleRNN\n",
    "is generally too simplistic for real use.\n",
    "\n",
    "The chief problem of RNN is that theoretically it should be able to \n",
    "retain at time t information about inputs seen many timesteps before, \n",
    "in practice, such long-term dependecies are impossible to learn. \n",
    "\n",
    "This is due to the ___Vanishing Gradient___ issue; which occurrs even\n",
    "in feedforward networks that are too deep:\n",
    "    because as you add layers to the network, it becomes untrainable\n",
    "\n",
    "The famous LSTM, adds a way to carry information across multiple \n",
    "timesteps. \n",
    "It saves information for later, thus preventing older signals\n",
    "from gradually vanishing during preprocessing. \n",
    "   \n",
    "   \n",
    "LSTM in Keras :DDDDDDDDDD\n",
    "\"\"\"\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics=[\"acc\"])\n",
    "history = model.fit(input_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=128,\n",
    "                   validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
      "420551\n"
     ]
    }
   ],
   "source": [
    "# LSTM => 89% accuracy!!\n",
    "\n",
    "\"\"\"\n",
    "Preprocess the data to a format a neural network can digest. \n",
    "If data is numerical no vectorization is needed. \n",
    "But each timeseries in the data is on a different scale\n",
    "    => Data should be normalized; \n",
    "The timeseries should be normalized independently so that the values \n",
    "they take are on a similar scale\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "data_dir = \"/home/kejsi/Downloads/jena_climate\"\n",
    "fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split(\"\\n\")\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all lines into a numpy array\n",
    "import numpy as np\n",
    "\n",
    "float_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(',')[1:]]\n",
    "    float_data[i, :] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efffa9abf60>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "temp = float_data[:, 1] # temperature (in degrees Celsius)\n",
    "plt.plot(range(len(temp)), temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efffa92dc50>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1440), temp[:1440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "\"\"\"\n",
    "The exact formulation of the problem will be as follows: given data going as far back\n",
    "as lookback timesteps (a timestep is 10 minutes) and sampled every steps timesteps,\n",
    "can you predict the temperature in delay timesteps? You’ll use the following parameter values\n",
    "\"\"\"\n",
    "lookback = 720 # Observations will go back 5 days??\n",
    "steps = 6 # Observations will be sampled at one data point per hour\n",
    "delay = 144 # Targets will be 24 hours in the future\n",
    "\"\"\"\n",
    "Two Things are needed though:\n",
    "1. Preprocess the data to a format a neural network can ingest. \n",
    "This is easy: the data is already numerical, so you dont need \n",
    "any vectorization. But each timeseries in the data is on a \n",
    "different scale => normalize timeseries INDEPENDENTLY!!!so as to take \n",
    "small values in similar scale\n",
    "\n",
    "2. Python generator that takes the current array of float\n",
    "data and yields batches of data from the recent past, along with \n",
    "a temp in the future. \n",
    "Because the samples in the dataset are highly redundant \n",
    "it would be wasteful to explicitly allocate each sample; \n",
    "Instead, you'll generate the samples on the fly using the original \n",
    "data\n",
    "\n",
    "The data will be preprocessed by subtracting the mean \n",
    "of each timeseries and dividing by the standard deviation. \n",
    "We'll use the first 200.000 timesteps as training data, \n",
    "so compute the mean and std only on this fraction of data. \n",
    "\"\"\"\n",
    "\n",
    "# normalizing:\n",
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.33 shows the data generator you’ll use. It yields a tuple (samples, targets),\n",
    "# where samples is one batch of input data and targets is the corresponding array of\n",
    "# target temperatures. It takes the following arguments\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "             shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "            min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "                rows = np.arange(i, min(i + batch_size, max_index))\n",
    "                i += len(rows)\n",
    "        samples = np.zeros((len(rows),\n",
    "                            lookback // step,\n",
    "                            data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNow, let’s use the abstract generator function to instantiate three generators: one for\\ntraining, one for validation, and one for testing. Each will look at different temporal\\nsegments of the original data: the training generator looks at the first 200,000 timesteps, the validation generator looks at the following 100,000, and the test generator\\nlooks at the remainder.\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, let’s use the abstract generator function to instantiate three generators: one for\n",
    "training, one for validation, and one for testing. Each will look at different temporal\n",
    "segments of the original data: the training generator looks at the first 200,000 timesteps, the validation generator looks at the following 100,000, and the test generator\n",
    "looks at the remainder.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 1440\n",
    "step = 6\n",
    "delay = 144\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(float_data,\n",
    "                        lookback=lookback,\n",
    "                        delay=delay,\n",
    "                        min_index=0,\n",
    "                        max_index=200000,\n",
    "                        shuffle=True,\n",
    "                        step=step,\n",
    "                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = generator(float_data,\n",
    "                        lookback=lookback,\n",
    "                        delay=delay,\n",
    "                        min_index=200001,\n",
    "                        max_index=300000,\n",
    "                        step=step,\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "test_gen = generator(float_data,\n",
    "                        lookback=lookback,\n",
    "                        delay=delay,\n",
    "                        min_index=300001,\n",
    "                        max_index=None,\n",
    "                        step=step,\n",
    "                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_steps = (300000 - 200001 - lookback)\n",
    "test_steps = (len(float_data) - 300001 - lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "model = Sequential()\n",
    "model.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1])))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "495/500 [============================>.] - ETA: 0s - loss: 1.4918"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'rows' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ee757dd1bea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     validation_steps=val_steps)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    228\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1467\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m_data_generator_task\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    656\u001b[0m                             \u001b[0;31m# => Serialize calls to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                             \u001b[0;31m# infinite iterator/generator's next() function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e4c62d9b2487>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(data, lookback, delay, min_index, max_index, shuffle, batch_size, step)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         samples = np.zeros((len(rows),\n\u001b[0m\u001b[1;32m     19\u001b[0m                             \u001b[0mlookback\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                             data.shape[-1]))\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'rows' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=500,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "358/500 [====================>.........] - ETA: 17s - loss: 0.3539"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d0f654f29b95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                 validation_steps=val_steps)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32,\n",
    "                        dropout=0.2,\n",
    "                        recurrent_dropout=0.2,\n",
    "                        input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                                steps_per_epoch=500,\n",
    "                                epochs=40,\n",
    "                                validation_data=val_gen,\n",
    "                                validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
